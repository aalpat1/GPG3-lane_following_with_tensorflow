{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.contrib.framework.python.ops.variables import get_or_create_global_step\n",
    "from inception_resnet_v2 import inception_resnet_v2, inception_resnet_v2_arg_scope\n",
    "import matplotlib.image as mpimg\n",
    "from dlproject import get_label_mapping, get_files, bottle_neck_process\n",
    "slim = tf.contrib.slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "checkpoint_file = './inception_resnet_v2_2016_08_30.ckpt'\n",
    "label_file = './labels.txt'\n",
    "train_file = 'Data/'\n",
    "bottle_neck_file = './bottle_neck/'\n",
    "save_model_file = './model_file/inception_resnet_v2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 720, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img=mpimg.imread(train_file + '/a/0.jpg')\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images = tf.placeholder(tf.float32, shape=(None, 480, 720, 3))\n",
    "labels = tf.placeholder(tf.int32, shape=(None,))\n",
    "\n",
    "# restore from the inception_resnet model\n",
    "with slim.arg_scope(inception_resnet_v2_arg_scope()):\n",
    "        _, end_points = inception_resnet_v2(images, num_classes = 1001, is_training = False) \n",
    "\n",
    "# extract the before_logit tensor from the extracted model\n",
    "before_logit = end_points['PreLogitsFlatten']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a placeholder for training from the bottle, not from the beginning.\n",
    "bottle_neck = tf.placeholder(tf.float32, shape=(None,1536))\n",
    "\n",
    "# now define the fine tune part of the graph\n",
    "with tf.name_scope('my_fine_tune') as scope:\n",
    "    batch_norm1 = tf.layers.batch_normalization(bottle_neck, name='batch_norm1')\n",
    "    dropout1 = tf.layers.dropout(batch_norm1, rate=0.3, name='dropout1')\n",
    "    dense1 = tf.layers.dense(dropout1, 128, activation=tf.nn.relu, name='dense1')\n",
    "    batch_norm2 = tf.layers.batch_normalization(dense1, name='batch_norm2')\n",
    "    dropout2 = tf.layers.dropout(batch_norm2, rate = 0.3, name='dropout2')\n",
    "    logits = tf.layers.dense(dropout2, 3, name='logits')\n",
    "    \n",
    "    x_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=labels)\n",
    "    loss = tf.reduce_mean(x_entropy, name='loss')\n",
    "    correct = tf.nn.in_top_k(logits, labels, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    \n",
    "    # extract variables that need to be trained\n",
    "    weight1, bias1 = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'dense1')\n",
    "    weight2, bias2 = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'logits')\n",
    "    variables_to_train = [weight1, weight2, bias1, bias2]\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    train_op = slim.learning.create_train_op(loss, optimizer, variables_to_train=variables_to_train)\n",
    "\n",
    "# defiine the name scope we don't need to restore from inception_resnet\n",
    "exclude = ['InceptionResnetV2/AuxLogits', 'InceptionResnetV2/Logits',\n",
    "           'my_fine_tune/','dense1','logits','batch_norm']\n",
    "\n",
    "variables_to_restore = slim.get_variables_to_restore(exclude = exclude)\n",
    "saver = tf.train.Saver(variables_to_restore)\n",
    "init = tf.global_variables_initializer()\n",
    "builder = tf.saved_model.builder.SavedModelBuilder(save_model_file)\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.allow_soft_placement = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# extract the data before the fine tune layer\n",
    "def get_bottle_neck_data(sess, train_file, bottle_neck_file, label_file):\n",
    "    id2label, label2id = get_label_mapping(label_file)\n",
    "    for i in id2label:\n",
    "        read_dir = train_file + i\n",
    "        des_dir = bottle_neck_file + i + '/'\n",
    "        os.mkdir(des_dir)\n",
    "        \n",
    "        files = get_files(read_dir)\n",
    "        for f in files:\n",
    "            img=mpimg.imread(f).reshape(1,480,720,3) / 255\n",
    "            bottle = sess.run(before_logit, feed_dict={images:img})\n",
    "            np.save(des_dir + f[7:],  bottle)\n",
    "            print('save the bottle neck file ' + f)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_graph(sess):\n",
    "    sess.run(init)\n",
    "    saver.restore(sess, checkpoint_file)\n",
    "\n",
    "    # if there is no dir for the bottle data, then get the data first.\n",
    "    if(os.path.isdir(bottle_neck_file) is not True):\n",
    "        os.mkdir(bottle_neck_file)\n",
    "        get_bottle_neck_data(sess, train_file, bottle_neck_file, label_file)\n",
    "\n",
    "    # get training data from bottle_neck file, and train.\n",
    "    bottle_neck_processor = bottle_neck_process(bottle_neck_file, label_file) \n",
    "    for i in range(1500):\n",
    "        inputs, groud_truth = bottle_neck_processor.next_batch(128)\n",
    "        train_loss, train_accuracy = sess.run([train_op, accuracy], feed_dict={bottle_neck: inputs, \n",
    "                                                                             labels: groud_truth})\n",
    "\n",
    "        if(i % 50 == 0):\n",
    "            val_loss, val_accuracy = sess.run([loss, accuracy],\n",
    "                                              feed_dict={bottle_neck: bottle_neck_processor.val_inputs,\n",
    "                                                         labels: bottle_neck_processor.val_labels})\n",
    "        \n",
    "            print('####################################')\n",
    "            print('the training loss after ' + str(i) + ' iterations is: ' + str(train_loss))\n",
    "            print('the training accuracy after ' + str(i) + ' iterations is: ' + str(train_accuracy))\n",
    "            print('the val loss after ' + str(i) + ' iterations is: ' + str(val_loss))\n",
    "            print('the val accuracy after ' + str(i) + ' iterations is: ' + str(val_accuracy))\n",
    "        \n",
    "#         after the training process finished, store the model to a '.pb' version file.\n",
    "    builder.add_meta_graph_and_variables(sess, [tf.saved_model.tag_constants.TRAINING],\n",
    "                                         signature_def_map=None, assets_collection=None)\n",
    "    \n",
    "    builder.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./inception_resnet_v2_2016_08_30.ckpt\n",
      "####################################\n",
      "the training loss after 0 iterations is: 1.21827\n",
      "the training accuracy after 0 iterations is: 0.165354\n",
      "the val loss after 0 iterations is: 0.899846\n",
      "the val accuracy after 0 iterations is: 0.66443\n",
      "####################################\n",
      "the training loss after 50 iterations is: 0.482014\n",
      "the training accuracy after 50 iterations is: 0.80315\n",
      "the val loss after 50 iterations is: 0.557199\n",
      "the val accuracy after 50 iterations is: 0.785235\n",
      "####################################\n",
      "the training loss after 100 iterations is: 0.382732\n",
      "the training accuracy after 100 iterations is: 0.811024\n",
      "the val loss after 100 iterations is: 0.556619\n",
      "the val accuracy after 100 iterations is: 0.771812\n",
      "####################################\n",
      "the training loss after 150 iterations is: 0.324867\n",
      "the training accuracy after 150 iterations is: 0.88189\n",
      "the val loss after 150 iterations is: 0.5465\n",
      "the val accuracy after 150 iterations is: 0.791946\n",
      "####################################\n",
      "the training loss after 200 iterations is: 0.300337\n",
      "the training accuracy after 200 iterations is: 0.858268\n",
      "the val loss after 200 iterations is: 0.508475\n",
      "the val accuracy after 200 iterations is: 0.805369\n",
      "####################################\n",
      "the training loss after 250 iterations is: 0.287026\n",
      "the training accuracy after 250 iterations is: 0.905512\n",
      "the val loss after 250 iterations is: 0.505859\n",
      "the val accuracy after 250 iterations is: 0.805369\n",
      "####################################\n",
      "the training loss after 300 iterations is: 0.257531\n",
      "the training accuracy after 300 iterations is: 0.92126\n",
      "the val loss after 300 iterations is: 0.491321\n",
      "the val accuracy after 300 iterations is: 0.798658\n",
      "####################################\n",
      "the training loss after 350 iterations is: 0.18738\n",
      "the training accuracy after 350 iterations is: 0.929134\n",
      "the val loss after 350 iterations is: 0.51458\n",
      "the val accuracy after 350 iterations is: 0.818792\n",
      "####################################\n",
      "the training loss after 400 iterations is: 0.208972\n",
      "the training accuracy after 400 iterations is: 0.929134\n",
      "the val loss after 400 iterations is: 0.503088\n",
      "the val accuracy after 400 iterations is: 0.812081\n",
      "####################################\n",
      "the training loss after 450 iterations is: 0.220816\n",
      "the training accuracy after 450 iterations is: 0.905512\n",
      "the val loss after 450 iterations is: 0.49471\n",
      "the val accuracy after 450 iterations is: 0.818792\n",
      "####################################\n",
      "the training loss after 500 iterations is: 0.169674\n",
      "the training accuracy after 500 iterations is: 0.937008\n",
      "the val loss after 500 iterations is: 0.491359\n",
      "the val accuracy after 500 iterations is: 0.825503\n",
      "####################################\n",
      "the training loss after 550 iterations is: 0.202063\n",
      "the training accuracy after 550 iterations is: 0.929134\n",
      "the val loss after 550 iterations is: 0.528116\n",
      "the val accuracy after 550 iterations is: 0.818792\n",
      "####################################\n",
      "the training loss after 600 iterations is: 0.155648\n",
      "the training accuracy after 600 iterations is: 0.952756\n",
      "the val loss after 600 iterations is: 0.513312\n",
      "the val accuracy after 600 iterations is: 0.812081\n",
      "####################################\n",
      "the training loss after 650 iterations is: 0.154221\n",
      "the training accuracy after 650 iterations is: 0.937008\n",
      "the val loss after 650 iterations is: 0.508043\n",
      "the val accuracy after 650 iterations is: 0.818792\n",
      "####################################\n",
      "the training loss after 700 iterations is: 0.137938\n",
      "the training accuracy after 700 iterations is: 0.952756\n",
      "the val loss after 700 iterations is: 0.561747\n",
      "the val accuracy after 700 iterations is: 0.778524\n",
      "####################################\n",
      "the training loss after 750 iterations is: 0.109044\n",
      "the training accuracy after 750 iterations is: 0.968504\n",
      "the val loss after 750 iterations is: 0.521814\n",
      "the val accuracy after 750 iterations is: 0.838926\n",
      "####################################\n",
      "the training loss after 800 iterations is: 0.108212\n",
      "the training accuracy after 800 iterations is: 0.992126\n",
      "the val loss after 800 iterations is: 0.534621\n",
      "the val accuracy after 800 iterations is: 0.832215\n",
      "####################################\n",
      "the training loss after 850 iterations is: 0.108118\n",
      "the training accuracy after 850 iterations is: 0.976378\n",
      "the val loss after 850 iterations is: 0.552028\n",
      "the val accuracy after 850 iterations is: 0.832215\n",
      "####################################\n",
      "the training loss after 900 iterations is: 0.115632\n",
      "the training accuracy after 900 iterations is: 0.968504\n",
      "the val loss after 900 iterations is: 0.571976\n",
      "the val accuracy after 900 iterations is: 0.812081\n",
      "####################################\n",
      "the training loss after 950 iterations is: 0.0758437\n",
      "the training accuracy after 950 iterations is: 1.0\n",
      "the val loss after 950 iterations is: 0.585179\n",
      "the val accuracy after 950 iterations is: 0.818792\n",
      "####################################\n",
      "the training loss after 1000 iterations is: 0.084263\n",
      "the training accuracy after 1000 iterations is: 0.992126\n",
      "the val loss after 1000 iterations is: 0.586467\n",
      "the val accuracy after 1000 iterations is: 0.812081\n",
      "####################################\n",
      "the training loss after 1050 iterations is: 0.0816706\n",
      "the training accuracy after 1050 iterations is: 0.984252\n",
      "the val loss after 1050 iterations is: 0.601694\n",
      "the val accuracy after 1050 iterations is: 0.812081\n",
      "####################################\n",
      "the training loss after 1100 iterations is: 0.0600213\n",
      "the training accuracy after 1100 iterations is: 0.992126\n",
      "the val loss after 1100 iterations is: 0.61091\n",
      "the val accuracy after 1100 iterations is: 0.812081\n",
      "####################################\n",
      "the training loss after 1150 iterations is: 0.081166\n",
      "the training accuracy after 1150 iterations is: 1.0\n",
      "the val loss after 1150 iterations is: 0.633198\n",
      "the val accuracy after 1150 iterations is: 0.805369\n",
      "####################################\n",
      "the training loss after 1200 iterations is: 0.0719824\n",
      "the training accuracy after 1200 iterations is: 0.992126\n",
      "the val loss after 1200 iterations is: 0.636736\n",
      "the val accuracy after 1200 iterations is: 0.812081\n",
      "####################################\n",
      "the training loss after 1250 iterations is: 0.048139\n",
      "the training accuracy after 1250 iterations is: 1.0\n",
      "the val loss after 1250 iterations is: 0.676639\n",
      "the val accuracy after 1250 iterations is: 0.838926\n",
      "####################################\n",
      "the training loss after 1300 iterations is: 0.0453567\n",
      "the training accuracy after 1300 iterations is: 1.0\n",
      "the val loss after 1300 iterations is: 0.660101\n",
      "the val accuracy after 1300 iterations is: 0.818792\n",
      "####################################\n",
      "the training loss after 1350 iterations is: 0.0513659\n",
      "the training accuracy after 1350 iterations is: 0.992126\n",
      "the val loss after 1350 iterations is: 0.671546\n",
      "the val accuracy after 1350 iterations is: 0.771812\n",
      "####################################\n",
      "the training loss after 1400 iterations is: 0.0598536\n",
      "the training accuracy after 1400 iterations is: 0.992126\n",
      "the val loss after 1400 iterations is: 0.69724\n",
      "the val accuracy after 1400 iterations is: 0.818792\n",
      "####################################\n",
      "the training loss after 1450 iterations is: 0.0292367\n",
      "the training accuracy after 1450 iterations is: 1.0\n",
      "the val loss after 1450 iterations is: 0.700003\n",
      "the val accuracy after 1450 iterations is: 0.818792\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(config=config) as sess:\n",
    "    train_graph(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
