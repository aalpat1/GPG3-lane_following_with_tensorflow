{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.contrib.framework.python.ops.variables import get_or_create_global_step\n",
    "from inception_resnet_v2 import inception_resnet_v2, inception_resnet_v2_arg_scope\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib\n",
    "from CNN_data_preprocess import get_label_mapping, get_files, bottle_neck_process\n",
    "slim = tf.contrib.slim\n",
    "from color_filter import red_filtered, blue_filtered\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "checkpoint_file = './model_file/inception_resnet_v2_2016_08_30.ckpt'\n",
    "label_file = './labels.txt'\n",
    "train_file = './Data9_10_sum/'\n",
    "bottle_neck_file = './middle_data/bottle_neck9_10_sum/'\n",
    "save_model_file = './model_file/inception_resnet_v2_for9_10_sum'\n",
    "last_layer_file = './middle_data/last_layer9_10_sum/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def build_graph():\n",
    "images = tf.placeholder(tf.float32, shape=(None, 480, 720, 3))\n",
    "labels = tf.placeholder(tf.int32, shape=(None,))\n",
    "\n",
    "# restore from the inception_resnet model\n",
    "with slim.arg_scope(inception_resnet_v2_arg_scope()):\n",
    "        _, end_points = inception_resnet_v2(images, num_classes = 1001, is_training = False) \n",
    "\n",
    "# extract the before_logit tensor from the extracted model\n",
    "before_logit = end_points['PreLogitsFlatten']\n",
    "\n",
    "\n",
    "# define a placeholder for training from the bottle, not from the beginning.\n",
    "bottle_neck = tf.placeholder(tf.float32, shape=(None,1536 * 2))\n",
    "\n",
    "# now define the fine tune part of the graph\n",
    "with tf.name_scope('my_fine_tune') as scope:\n",
    "#     dropout = tf.layers.dropout(bottle_neck, rate=0.3, name='dropout')\n",
    "    batch_norm1 = tf.layers.batch_normalization(bottle_neck, name='batch_norm1')\n",
    "    dropout1 = tf.layers.dropout(batch_norm1, rate=0.3, name='dropout1')\n",
    "    dense1 = tf.layers.dense(dropout1, 512, activation=tf.nn.relu, name='dense1')\n",
    "    batch_norm2 = tf.layers.batch_normalization(dense1, name='batch_norm2')\n",
    "    dropout2 = tf.layers.dropout(batch_norm2, rate = 0.3, name='dropout2')\n",
    "    dense2 = tf.layers.dense(dropout2, 128, activation=tf.nn.relu, name='dense2')\n",
    "    batch_norm3 = tf.layers.batch_normalization(dense2, name='batch_norm3')\n",
    "    dropout3 = tf.layers.dropout(batch_norm3, rate = 0.3, name='dropout3')\n",
    "    logits = tf.layers.dense(dropout3, 3, name='logits')\n",
    "\n",
    "    x_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=labels)\n",
    "    loss = tf.reduce_mean(x_entropy, name='loss')\n",
    "    correct = tf.nn.in_top_k(logits, labels, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "    # extract variables that need to be trained\n",
    "    weight1, bias1 = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'dense1')\n",
    "    weight2, bias2 = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'logits')\n",
    "    variables_to_train = [weight1, weight2, bias1, bias2]\n",
    "\n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    train_op = slim.learning.create_train_op(loss, optimizer, variables_to_train=variables_to_train)\n",
    "\n",
    "# defiine the name scope we don't need to restore from inception_resnet\n",
    "exclude = ['InceptionResnetV2/AuxLogits', 'InceptionResnetV2/Logits',\n",
    "           'my_fine_tune/','dense','logits','batch_norm']\n",
    "\n",
    "variables_to_restore = slim.get_variables_to_restore(exclude = exclude)\n",
    "saver = tf.train.Saver(variables_to_restore)\n",
    "init = tf.global_variables_initializer()\n",
    "builder = tf.saved_model.builder.SavedModelBuilder(save_model_file)\n",
    "\n",
    "#     return images, labels, before_logit, bottle_neck,batch_norm2, loss, accuracy, train_op, saver, init, builder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"InceptionResnetV2/Logits/Dropout/Identity:0\", shape=(?, 1536), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(before_logit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def listdir_nohidden(path):\n",
    "    for f in os.listdir(path):\n",
    "        if not f.startswith('.'):\n",
    "            yield f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# extract the data before the fine tune layer\n",
    "def get_bottle_neck_data(sess, before_logit, images, train_file, bottle_neck_file, label_file, hsv = False):\n",
    "    id2label, label2id = get_label_mapping(label_file)\n",
    "    for i in id2label:\n",
    "        read_dir = train_file + i\n",
    "        des_dir = bottle_neck_file + i + '/'\n",
    "        os.mkdir(des_dir)\n",
    "        \n",
    "        files = get_files(read_dir)\n",
    "        for f in files:\n",
    "            img = mpimg.imread(f).reshape(1,480,720,3) / 255\n",
    "            img1 = cv2.imread(f)\n",
    "            img2=red_filtered(img1)[1].reshape(1,480,720,3) / 255\n",
    "            img3=blue_filtered(img1)[1].reshape(1,480,720,3) / 255\n",
    "            if(hsv):\n",
    "                img = matplotlib.colors.rgb_to_hsv(img)\n",
    "            bottle = sess.run(before_logit, feed_dict={images:img})\n",
    "            bottle1 = sess.run(before_logit, feed_dict={images:img2})\n",
    "            bottle2 = sess.run(before_logit, feed_dict={images:img3})\n",
    "            bottle = np.concatenate((bottle, bottle1), axis = 1)\n",
    "            bottle = np.concatenate((bottle, bottle2), axis = 1)\n",
    "            print(bottle.shape)\n",
    "            np.save(des_dir + f[len(read_dir):],  bottle)\n",
    "            print('save the bottle neck file ' + f)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_bottle_neck_data_timestamp(sess, before_logit, images, train_file, bottle_neck_file, label_file, hsv = False):\n",
    "    os.mkdir(bottle_neck_file)\n",
    "    folders = listdir_nohidden(train_file)\n",
    "    print(bottle_neck_file)\n",
    "    for folder in folders:\n",
    "        train_actual = train_file + folder + '/'\n",
    "        bottle_neck_actual = bottle_neck_file + folder + '/'\n",
    "        print(train_actual)\n",
    "        print(bottle_neck_actual)\n",
    "        os.mkdir(bottle_neck_actual)\n",
    "        get_bottle_neck_data(sess, before_logit, images, train_actual, bottle_neck_actual, label_file, hsv = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_accuracy(sess):\n",
    "    sess.run(init)\n",
    "    saver.restore(sess, checkpoint_file)\n",
    "    \n",
    "    bottle_neck_processor = bottle_neck_process(bottle_neck_file, label_file) \n",
    "\n",
    "    val_loss, val_accuracy = sess.run([loss, accuracy],\n",
    "                                              feed_dict={bottle_neck: bottle_neck_processor.val_inputs,\n",
    "                                                         labels: bottle_neck_processor.val_labels})\n",
    "    \n",
    "    for i in bottle_neck_processor.id2label:\n",
    "        val_accuracy = sess.run([accuracy],\n",
    "                              feed_dict={bottle_neck: bottle_neck_processor.val_inputs_each[i],\n",
    "                                         labels: bottle_neck_processor.val_labels_each[i]})\n",
    "        print(i + ': the val accuracy is: '  + str(val_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_graph(sess):\n",
    "#     images, labels, before_logit, bottle_neck, batch_norm2, loss, accuracy, train_op, saver, init, builder = model_list\n",
    "    \n",
    "    sess.run(init)\n",
    "    saver.restore(sess, checkpoint_file)\n",
    "\n",
    "    # if there is no dir for the bottle data, then get the data first.\n",
    "    if(os.path.isdir(bottle_neck_file) is not True):\n",
    "        os.mkdir(bottle_neck_file)\n",
    "        get_bottle_neck_data(sess, before_logit, images, train_file, bottle_neck_file, label_file, hsv = False)\n",
    "\n",
    "    # get training data from bottle_neck file, and train.\n",
    "    bottle_neck_processor = bottle_neck_process(bottle_neck_file, label_file) \n",
    "    for i in range(2000):\n",
    "        inputs, groud_truth = bottle_neck_processor.next_batch(256)\n",
    "        train_loss, train_accuracy = sess.run([train_op, accuracy], feed_dict={bottle_neck: inputs, \n",
    "                                                                             labels: groud_truth})\n",
    "\n",
    "        if(i % 50 == 0):\n",
    "            val_loss, val_accuracy = sess.run([loss, accuracy],\n",
    "                                              feed_dict={bottle_neck: bottle_neck_processor.val_inputs,\n",
    "                                                         labels: bottle_neck_processor.val_labels})\n",
    "        \n",
    "            print('####################################')\n",
    "            print('the training loss after ' + str(i) + ' iterations is: ' + str(train_loss))\n",
    "            print('the training accuracy after ' + str(i) + ' iterations is: ' + str(train_accuracy))\n",
    "            print('the val loss after ' + str(i) + ' iterations is: ' + str(val_loss))\n",
    "            print('the val accuracy after ' + str(i) + ' iterations is: ' + str(val_accuracy))\n",
    "            print('-------------')\n",
    "            \n",
    "            for i in bottle_neck_processor.id2label:\n",
    "                val_accuracy = sess.run([accuracy],\n",
    "                                      feed_dict={bottle_neck: bottle_neck_processor.val_inputs_each[i],\n",
    "                                                 labels: bottle_neck_processor.val_labels_each[i]})\n",
    "                print(i + ': the val accuracy is: '  + str(val_accuracy))\n",
    "        \n",
    "#         after the training process finished, store the model to a '.pb' version file.\n",
    "    builder.add_meta_graph_and_variables(sess, [tf.saved_model.tag_constants.TRAINING],\n",
    "                                         signature_def_map=None, assets_collection=None)\n",
    "    \n",
    "    builder.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model_file/inception_resnet_v2_2016_08_30.ckpt\n",
      "./middle_data/bottle_neck9_10_sum/a\n",
      "654\n",
      "the lengeh of inputs is 654\n",
      "./middle_data/bottle_neck9_10_sum/d\n",
      "131\n",
      "the lengeh of inputs is 131\n",
      "./middle_data/bottle_neck9_10_sum/w\n",
      "1924\n",
      "the lengeh of inputs is 1924\n",
      "####################################\n",
      "the training loss after 0 iterations is: 1.14709\n",
      "the training accuracy after 0 iterations is: 0.244094\n",
      "the val loss after 0 iterations is: 0.885996\n",
      "the val accuracy after 0 iterations is: 0.711111\n",
      "-------------\n",
      "a: the val accuracy is: [0.0]\n",
      "d: the val accuracy is: [0.0]\n",
      "w: the val accuracy is: [1.0]\n",
      "####################################\n",
      "the training loss after 50 iterations is: 0.432325\n",
      "the training accuracy after 50 iterations is: 0.834646\n",
      "the val loss after 50 iterations is: 0.495412\n",
      "the val accuracy after 50 iterations is: 0.82963\n",
      "-------------\n",
      "a: the val accuracy is: [0.61538464]\n",
      "d: the val accuracy is: [0.0]\n",
      "w: the val accuracy is: [0.95833331]\n",
      "####################################\n",
      "the training loss after 100 iterations is: 0.395417\n",
      "the training accuracy after 100 iterations is: 0.866142\n",
      "the val loss after 100 iterations is: 0.457669\n",
      "the val accuracy after 100 iterations is: 0.82963\n",
      "-------------\n",
      "a: the val accuracy is: [0.66153848]\n",
      "d: the val accuracy is: [0.0]\n",
      "w: the val accuracy is: [0.94270831]\n",
      "####################################\n",
      "the training loss after 150 iterations is: 0.354317\n",
      "the training accuracy after 150 iterations is: 0.874016\n",
      "the val loss after 150 iterations is: 0.443854\n",
      "the val accuracy after 150 iterations is: 0.846296\n",
      "-------------\n",
      "a: the val accuracy is: [0.69999999]\n",
      "d: the val accuracy is: [0.03846154]\n",
      "w: the val accuracy is: [0.95052081]\n",
      "####################################\n",
      "the training loss after 200 iterations is: 0.307896\n",
      "the training accuracy after 200 iterations is: 0.88189\n",
      "the val loss after 200 iterations is: 0.436744\n",
      "the val accuracy after 200 iterations is: 0.85\n",
      "-------------\n",
      "a: the val accuracy is: [0.68461537]\n",
      "d: the val accuracy is: [0.0]\n",
      "w: the val accuracy is: [0.96354169]\n",
      "####################################\n",
      "the training loss after 250 iterations is: 0.304857\n",
      "the training accuracy after 250 iterations is: 0.885827\n",
      "the val loss after 250 iterations is: 0.421336\n",
      "the val accuracy after 250 iterations is: 0.85\n",
      "-------------\n",
      "a: the val accuracy is: [0.7846154]\n",
      "d: the val accuracy is: [0.0]\n",
      "w: the val accuracy is: [0.9296875]\n",
      "####################################\n",
      "the training loss after 300 iterations is: 0.29034\n",
      "the training accuracy after 300 iterations is: 0.897638\n",
      "the val loss after 300 iterations is: 0.45546\n",
      "the val accuracy after 300 iterations is: 0.842593\n",
      "-------------\n",
      "a: the val accuracy is: [0.64615387]\n",
      "d: the val accuracy is: [0.30769232]\n",
      "w: the val accuracy is: [0.9453125]\n",
      "####################################\n",
      "the training loss after 350 iterations is: 0.26548\n",
      "the training accuracy after 350 iterations is: 0.905512\n",
      "the val loss after 350 iterations is: 0.406039\n",
      "the val accuracy after 350 iterations is: 0.837037\n",
      "-------------\n",
      "a: the val accuracy is: [0.77692306]\n",
      "d: the val accuracy is: [0.07692308]\n",
      "w: the val accuracy is: [0.90885419]\n",
      "####################################\n",
      "the training loss after 400 iterations is: 0.307281\n",
      "the training accuracy after 400 iterations is: 0.858268\n",
      "the val loss after 400 iterations is: 0.405743\n",
      "the val accuracy after 400 iterations is: 0.844444\n",
      "-------------\n",
      "a: the val accuracy is: [0.72307694]\n",
      "d: the val accuracy is: [0.15384616]\n",
      "w: the val accuracy is: [0.93229169]\n",
      "####################################\n",
      "the training loss after 450 iterations is: 0.222007\n",
      "the training accuracy after 450 iterations is: 0.897638\n",
      "the val loss after 450 iterations is: 0.411676\n",
      "the val accuracy after 450 iterations is: 0.844444\n",
      "-------------\n",
      "a: the val accuracy is: [0.69230771]\n",
      "d: the val accuracy is: [0.0]\n",
      "w: the val accuracy is: [0.953125]\n",
      "####################################\n",
      "the training loss after 500 iterations is: 0.255216\n",
      "the training accuracy after 500 iterations is: 0.893701\n",
      "the val loss after 500 iterations is: 0.41374\n",
      "the val accuracy after 500 iterations is: 0.842593\n",
      "-------------\n",
      "a: the val accuracy is: [0.7153846]\n",
      "d: the val accuracy is: [0.15384616]\n",
      "w: the val accuracy is: [0.93229169]\n",
      "####################################\n",
      "the training loss after 550 iterations is: 0.180204\n",
      "the training accuracy after 550 iterations is: 0.913386\n",
      "the val loss after 550 iterations is: 0.407718\n",
      "the val accuracy after 550 iterations is: 0.848148\n",
      "-------------\n",
      "a: the val accuracy is: [0.73846155]\n",
      "d: the val accuracy is: [0.26923078]\n",
      "w: the val accuracy is: [0.92447919]\n",
      "####################################\n",
      "the training loss after 600 iterations is: 0.194788\n",
      "the training accuracy after 600 iterations is: 0.933071\n",
      "the val loss after 600 iterations is: 0.420177\n",
      "the val accuracy after 600 iterations is: 0.842593\n",
      "-------------\n",
      "a: the val accuracy is: [0.73846155]\n",
      "d: the val accuracy is: [0.15384616]\n",
      "w: the val accuracy is: [0.92447919]\n",
      "####################################\n",
      "the training loss after 650 iterations is: 0.22296\n",
      "the training accuracy after 650 iterations is: 0.905512\n",
      "the val loss after 650 iterations is: 0.420696\n",
      "the val accuracy after 650 iterations is: 0.838889\n",
      "-------------\n",
      "a: the val accuracy is: [0.76153845]\n",
      "d: the val accuracy is: [0.34615386]\n",
      "w: the val accuracy is: [0.8984375]\n",
      "####################################\n",
      "the training loss after 700 iterations is: 0.219354\n",
      "the training accuracy after 700 iterations is: 0.913386\n",
      "the val loss after 700 iterations is: 0.428039\n",
      "the val accuracy after 700 iterations is: 0.842593\n",
      "-------------\n",
      "a: the val accuracy is: [0.75384617]\n",
      "d: the val accuracy is: [0.34615386]\n",
      "w: the val accuracy is: [0.90625]\n",
      "####################################\n",
      "the training loss after 750 iterations is: 0.122592\n",
      "the training accuracy after 750 iterations is: 0.96063\n",
      "the val loss after 750 iterations is: 0.45274\n",
      "the val accuracy after 750 iterations is: 0.844444\n",
      "-------------\n",
      "a: the val accuracy is: [0.66923076]\n",
      "d: the val accuracy is: [0.1923077]\n",
      "w: the val accuracy is: [0.94791669]\n",
      "####################################\n",
      "the training loss after 800 iterations is: 0.16284\n",
      "the training accuracy after 800 iterations is: 0.944882\n",
      "the val loss after 800 iterations is: 0.533574\n",
      "the val accuracy after 800 iterations is: 0.842593\n",
      "-------------\n",
      "a: the val accuracy is: [0.62307692]\n",
      "d: the val accuracy is: [0.46153846]\n",
      "w: the val accuracy is: [0.94270831]\n",
      "####################################\n",
      "the training loss after 850 iterations is: 0.171996\n",
      "the training accuracy after 850 iterations is: 0.933071\n",
      "the val loss after 850 iterations is: 0.43608\n",
      "the val accuracy after 850 iterations is: 0.840741\n",
      "-------------\n",
      "a: the val accuracy is: [0.73846155]\n",
      "d: the val accuracy is: [0.11538462]\n",
      "w: the val accuracy is: [0.92447919]\n",
      "####################################\n",
      "the training loss after 900 iterations is: 0.13598\n",
      "the training accuracy after 900 iterations is: 0.948819\n",
      "the val loss after 900 iterations is: 0.44049\n",
      "the val accuracy after 900 iterations is: 0.851852\n",
      "-------------\n",
      "a: the val accuracy is: [0.73846155]\n",
      "d: the val accuracy is: [0.38461539]\n",
      "w: the val accuracy is: [0.921875]\n",
      "####################################\n",
      "the training loss after 950 iterations is: 0.14884\n",
      "the training accuracy after 950 iterations is: 0.940945\n",
      "the val loss after 950 iterations is: 0.473754\n",
      "the val accuracy after 950 iterations is: 0.85\n",
      "-------------\n",
      "a: the val accuracy is: [0.69999999]\n",
      "d: the val accuracy is: [0.5]\n",
      "w: the val accuracy is: [0.92447919]\n",
      "####################################\n",
      "the training loss after 1000 iterations is: 0.169948\n",
      "the training accuracy after 1000 iterations is: 0.933071\n",
      "the val loss after 1000 iterations is: 0.488072\n",
      "the val accuracy after 1000 iterations is: 0.853704\n",
      "-------------\n",
      "a: the val accuracy is: [0.6769231]\n",
      "d: the val accuracy is: [0.53846157]\n",
      "w: the val accuracy is: [0.93489581]\n",
      "####################################\n",
      "the training loss after 1050 iterations is: 0.130295\n",
      "the training accuracy after 1050 iterations is: 0.940945\n",
      "the val loss after 1050 iterations is: 0.493143\n",
      "the val accuracy after 1050 iterations is: 0.844444\n",
      "-------------\n",
      "a: the val accuracy is: [0.72307694]\n",
      "d: the val accuracy is: [0.11538462]\n",
      "w: the val accuracy is: [0.93489581]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################################\n",
      "the training loss after 1100 iterations is: 0.144282\n",
      "the training accuracy after 1100 iterations is: 0.944882\n",
      "the val loss after 1100 iterations is: 0.459222\n",
      "the val accuracy after 1100 iterations is: 0.855556\n",
      "-------------\n",
      "a: the val accuracy is: [0.73846155]\n",
      "d: the val accuracy is: [0.42307693]\n",
      "w: the val accuracy is: [0.92447919]\n",
      "####################################\n",
      "the training loss after 1150 iterations is: 0.158547\n",
      "the training accuracy after 1150 iterations is: 0.944882\n",
      "the val loss after 1150 iterations is: 0.476122\n",
      "the val accuracy after 1150 iterations is: 0.844444\n",
      "-------------\n",
      "a: the val accuracy is: [0.69999999]\n",
      "d: the val accuracy is: [0.1923077]\n",
      "w: the val accuracy is: [0.9375]\n",
      "####################################\n",
      "the training loss after 1200 iterations is: 0.101127\n",
      "the training accuracy after 1200 iterations is: 0.972441\n",
      "the val loss after 1200 iterations is: 0.463425\n",
      "the val accuracy after 1200 iterations is: 0.846296\n",
      "-------------\n",
      "a: the val accuracy is: [0.76153845]\n",
      "d: the val accuracy is: [0.15384616]\n",
      "w: the val accuracy is: [0.921875]\n",
      "####################################\n",
      "the training loss after 1250 iterations is: 0.13167\n",
      "the training accuracy after 1250 iterations is: 0.944882\n",
      "the val loss after 1250 iterations is: 0.532472\n",
      "the val accuracy after 1250 iterations is: 0.848148\n",
      "-------------\n",
      "a: the val accuracy is: [0.66153848]\n",
      "d: the val accuracy is: [0.1923077]\n",
      "w: the val accuracy is: [0.95572919]\n",
      "####################################\n",
      "the training loss after 1300 iterations is: 0.173359\n",
      "the training accuracy after 1300 iterations is: 0.933071\n",
      "the val loss after 1300 iterations is: 0.497907\n",
      "the val accuracy after 1300 iterations is: 0.851852\n",
      "-------------\n",
      "a: the val accuracy is: [0.74615383]\n",
      "d: the val accuracy is: [0.65384614]\n",
      "w: the val accuracy is: [0.90104169]\n",
      "####################################\n",
      "the training loss after 1350 iterations is: 0.148852\n",
      "the training accuracy after 1350 iterations is: 0.964567\n",
      "the val loss after 1350 iterations is: 0.497789\n",
      "the val accuracy after 1350 iterations is: 0.831481\n",
      "-------------\n",
      "a: the val accuracy is: [0.74615383]\n",
      "d: the val accuracy is: [0.30769232]\n",
      "w: the val accuracy is: [0.89583331]\n",
      "####################################\n",
      "the training loss after 1400 iterations is: 0.115611\n",
      "the training accuracy after 1400 iterations is: 0.948819\n",
      "the val loss after 1400 iterations is: 0.516677\n",
      "the val accuracy after 1400 iterations is: 0.835185\n",
      "-------------\n",
      "a: the val accuracy is: [0.79230767]\n",
      "d: the val accuracy is: [0.30769232]\n",
      "w: the val accuracy is: [0.88541669]\n",
      "####################################\n",
      "the training loss after 1450 iterations is: 0.081534\n",
      "the training accuracy after 1450 iterations is: 0.968504\n",
      "the val loss after 1450 iterations is: 0.513996\n",
      "the val accuracy after 1450 iterations is: 0.844444\n",
      "-------------\n",
      "a: the val accuracy is: [0.80769229]\n",
      "d: the val accuracy is: [0.26923078]\n",
      "w: the val accuracy is: [0.89583331]\n",
      "####################################\n",
      "the training loss after 1500 iterations is: 0.144743\n",
      "the training accuracy after 1500 iterations is: 0.96063\n",
      "the val loss after 1500 iterations is: 0.574411\n",
      "the val accuracy after 1500 iterations is: 0.838889\n",
      "-------------\n",
      "a: the val accuracy is: [0.63846153]\n",
      "d: the val accuracy is: [0.11538462]\n",
      "w: the val accuracy is: [0.95572919]\n",
      "####################################\n",
      "the training loss after 1550 iterations is: 0.0943663\n",
      "the training accuracy after 1550 iterations is: 0.964567\n",
      "the val loss after 1550 iterations is: 0.535278\n",
      "the val accuracy after 1550 iterations is: 0.859259\n",
      "-------------\n",
      "a: the val accuracy is: [0.74615383]\n",
      "d: the val accuracy is: [0.57692307]\n",
      "w: the val accuracy is: [0.91666669]\n",
      "####################################\n",
      "the training loss after 1600 iterations is: 0.0839988\n",
      "the training accuracy after 1600 iterations is: 0.980315\n",
      "the val loss after 1600 iterations is: 0.520461\n",
      "the val accuracy after 1600 iterations is: 0.857407\n",
      "-------------\n",
      "a: the val accuracy is: [0.76153845]\n",
      "d: the val accuracy is: [0.53846157]\n",
      "w: the val accuracy is: [0.91145831]\n",
      "####################################\n",
      "the training loss after 1650 iterations is: 0.0968457\n",
      "the training accuracy after 1650 iterations is: 0.952756\n",
      "the val loss after 1650 iterations is: 0.539435\n",
      "the val accuracy after 1650 iterations is: 0.853704\n",
      "-------------\n",
      "a: the val accuracy is: [0.72307694]\n",
      "d: the val accuracy is: [0.34615386]\n",
      "w: the val accuracy is: [0.93229169]\n",
      "####################################\n",
      "the training loss after 1700 iterations is: 0.0858193\n",
      "the training accuracy after 1700 iterations is: 0.980315\n",
      "the val loss after 1700 iterations is: 0.53663\n",
      "the val accuracy after 1700 iterations is: 0.855556\n",
      "-------------\n",
      "a: the val accuracy is: [0.72307694]\n",
      "d: the val accuracy is: [0.34615386]\n",
      "w: the val accuracy is: [0.93489581]\n",
      "####################################\n",
      "the training loss after 1750 iterations is: 0.097147\n",
      "the training accuracy after 1750 iterations is: 0.956693\n",
      "the val loss after 1750 iterations is: 0.544464\n",
      "the val accuracy after 1750 iterations is: 0.855556\n",
      "-------------\n",
      "a: the val accuracy is: [0.69230771]\n",
      "d: the val accuracy is: [0.38461539]\n",
      "w: the val accuracy is: [0.94270831]\n",
      "####################################\n",
      "the training loss after 1800 iterations is: 0.110506\n",
      "the training accuracy after 1800 iterations is: 0.964567\n",
      "the val loss after 1800 iterations is: 0.59265\n",
      "the val accuracy after 1800 iterations is: 0.846296\n",
      "-------------\n",
      "a: the val accuracy is: [0.65384614]\n",
      "d: the val accuracy is: [0.5]\n",
      "w: the val accuracy is: [0.93489581]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    config = tf.ConfigProto()\n",
    "    config.allow_soft_placement = True\n",
    "    with tf.Session(config=config) as sess:\n",
    "        train_graph(sess)\n",
    "#         get_accuracy(sess)\n",
    "#         sess.run(init)\n",
    "#         saver.restore(sess, checkpoint_file)\n",
    "#         get_bottle_neck_data_timestamp(sess, before_logit, images, train_file, bottle_neck_file, label_file, hsv = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
