{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.misc\n",
    "import glob\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import os\n",
    "from os.path import basename\n",
    "import collections\n",
    "import tflearn\n",
    "from collections import deque\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tflearn.data_utils import to_categorical\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_img_array(path):\n",
    "    \"\"\"\n",
    "    Given path of image, returns it's numpy array\n",
    "    \"\"\"\n",
    "    return scipy.misc.imread(path)\n",
    "\n",
    "def check_files(folder):\n",
    "    \"\"\"\n",
    "    Given path to folder, returns whether it's empty or not\n",
    "    \"\"\"\n",
    "    filenames = [file for file in glob.glob(folder+'*/*')]\n",
    "    if(len(filenames)==0):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def get_files(folder):\n",
    "    \"\"\"\n",
    "    Given path to folder, returns list of files in it\n",
    "    \"\"\"\n",
    "    filenames = [file for file in glob.glob(folder+'*/*')]\n",
    "    filenames.sort()\n",
    "    return filenames\n",
    "\n",
    "def get_label(label2id, label):\n",
    "    \"\"\"\n",
    "    Returns label for a folder\n",
    "    \"\"\"\n",
    "    if label in label2id:\n",
    "        return label2id[label]\n",
    "    else:\n",
    "        sys.exit(\"Invalid label: \" + label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Functions to load data, DO NOT change these\n",
    "\n",
    "def get_labels(folder, label2id):\n",
    "    \"\"\"\n",
    "    Returns vector of labels extracted from filenames of all files in folder\n",
    "    :param folder: path to data folder\n",
    "    :param label2id: mapping of text labels to numeric ids. (Eg: automobile -> 0)\n",
    "    \"\"\"\n",
    "    files = get_files(folder)\n",
    "    y = []\n",
    "    for f in files:\n",
    "        y.append(get_label(f,label2id))\n",
    "    return np.array(y)\n",
    "\n",
    "def one_hot(y, num_classes=10):\n",
    "    \"\"\"\n",
    "    Converts each label index in y to vector with one_hot encoding\n",
    "    \"\"\"\n",
    "    y_one_hot = np.zeros((y.shape[0], num_classes))\n",
    "    y_one_hot[y] = 1\n",
    "    return y_one_hot.T\n",
    "\n",
    "def get_label_mapping(label_file):\n",
    "    \"\"\"\n",
    "    Returns mappings of label to index and index to label\n",
    "    The input file has list of labels, each on a separate line.\n",
    "    \"\"\"\n",
    "    with open(label_file, 'r') as f:\n",
    "        id2label = f.readlines()\n",
    "        id2label = [l.strip() for l in id2label]\n",
    "    label2id = {}\n",
    "    count = 0\n",
    "    for label in id2label:\n",
    "        label2id[label] = count\n",
    "        count += 1\n",
    "    return id2label, label2id\n",
    "\n",
    "def get_images(folder):\n",
    "    \"\"\"\n",
    "    returns numpy array of all samples in folder\n",
    "    each column is a sample resized to 30x30 and flattened\n",
    "    \"\"\"\n",
    "    files = get_files(folder)\n",
    "    images = []\n",
    "    count = 0\n",
    "    \n",
    "    for f in files:\n",
    "        count += 1\n",
    "        if count % 10000 == 0:\n",
    "            print(\"Loaded {}/{}\".format(count,len(files)))\n",
    "        img_arr = get_img_array(f)\n",
    "        img_arr = img_arr.flatten() / 255.0\n",
    "        images.append(img_arr)\n",
    "    X = np.column_stack(images)\n",
    "    return X\n",
    "\n",
    "def get_image_map(folder, label):\n",
    "    \"\"\"\n",
    "    returns numpy array of all samples in folder\n",
    "    each column is a sample resized to 30x30 and flattened\n",
    "    \"\"\"\n",
    "    image_map = {}\n",
    "    files = get_files(folder)\n",
    "    images = []\n",
    "    count = 0\n",
    "    \n",
    "    for f in files:\n",
    "        count += 1\n",
    "        if count % 10000 == 0:\n",
    "            print(\"Loaded {}/{}\".format(count,len(files)))\n",
    "        img_arr = np.load(f)\n",
    "        img_arr = img_arr.flatten()\n",
    "        name = basename(f)\n",
    "        num = int(name.split(\"_\")[1].split(\".\")[0])\n",
    "        image_map[num] = [img_arr, label]\n",
    "\n",
    "    return image_map\n",
    "\n",
    "def get_train_data(data_root_path, label_mapping_path):\n",
    "    \"\"\"\n",
    "    Return X and y\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    labels = os.listdir(data_root_path)\n",
    "    id2label, label2id = get_label_mapping(label_mapping_path)\n",
    "    print(label2id)\n",
    "    image_map = {}\n",
    "    for label in labels:\n",
    "        train_data_path = data_root_path + label\n",
    "        if(check_files(train_data_path)) :\n",
    "            temp_map = get_image_map(train_data_path, label)\n",
    "            image_map.update(temp_map)\n",
    "    new_map = collections.OrderedDict(sorted(image_map.items()))\n",
    "    for k, v in new_map.items():\n",
    "        X.append(v[0])\n",
    "        y.append(get_label(label2id, v[1]))\n",
    "    X = np.array(X)\n",
    "    return X, np.array(y)\n",
    "\n",
    "def save_predictions(filename, y):\n",
    "    \"\"\"\n",
    "    Dumps y into .npy file\n",
    "    \"\"\"\n",
    "    np.save(filename, y)# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data_with_seq(X_batch, y_batch, seq_length, num_classes, input_length):\n",
    "    \"\"\"\n",
    "    creates data where every data point has seq_length images\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    image_seq = deque()\n",
    "    for row in range(0,len(X_batch)):\n",
    "        image_seq.append(X_batch[row])\n",
    "        #y_list.append(y_from_image[row])\n",
    "        if len(image_seq) == seq_length:\n",
    "            X.append(np.array(list(image_seq)))\n",
    "            y.append(y_batch[row])\n",
    "            #y.append(np.array(list(y_list)))\n",
    "            image_seq.popleft()\n",
    "            #y_list.popleft()\n",
    "    \n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    #print(X.shape)\n",
    "    y = to_categorical(y, num_classes)\n",
    "    #print(y.shape)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify = y)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_data(root_path, label_mapping_path):\n",
    "    folders = os.listdir(root_path)\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    \n",
    "    input_length = 128\n",
    "    seq_length = 2\n",
    "    num_classes = 3\n",
    "    \n",
    "    for folder in folders:\n",
    "        data_root_path = root_path+folder+'/'\n",
    "        X_batch, y_batch = get_train_data(data_root_path, label_mapping_path)\n",
    "        X_train_batch, X_test_batch, y_train_batch, y_test_batch = get_data_with_seq(X_batch, y_batch, seq_length, num_classes, input_length)\n",
    "        X_train.extend(X_train_batch)\n",
    "        y_train.extend(y_train_batch)\n",
    "        X_test.extend(X_test_batch)\n",
    "        y_test.extend(y_test_batch)\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "    X_test = np.array(X_test)\n",
    "    y_test = np.array(y_test)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_rnn(images, input_size, num_classes):\n",
    "    rnn = tflearn.input_data(shape=[None, images, input_size])\n",
    "    rnn = tflearn.lstm(rnn, 512, dropout=0.8, return_seq=True)\n",
    "    rnn = tflearn.lstm(rnn, 512)\n",
    "    rnn = tflearn.fully_connected(rnn, num_classes, activation='softmax')\n",
    "    rnn = tflearn.regression(rnn, optimizer='adam',\n",
    "                             loss='categorical_crossentropy', name=\"output1\")\n",
    "    return rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train(X_train, y_train, X_test, y_test, seq_length, batch_size):\n",
    "    \n",
    "    \n",
    "    input_length = X_train.shape[2]\n",
    "    num_classes = len(y_train[0])\n",
    "    \n",
    "    rnn = get_rnn(seq_length, input_length, num_classes)\n",
    "\n",
    "    model = tflearn.DNN(rnn, tensorboard_verbose=1)\n",
    "    model.fit(X_train, y_train, validation_set=(X_test, y_test),\n",
    "              show_metric=True, batch_size=batch_size, snapshot_step=100,\n",
    "              n_epoch=3)\n",
    "    \n",
    "    #builder = tf.saved_model.builder.SavedModelBuilder('./modelPath1')\n",
    "    #builder.add_meta_graph_and_variables(model.session, [tf.saved_model.tag_constants.TRAINING],\n",
    "                                         #signature_def_map=None, assets_collection=None)\n",
    "    model.save('checkpoints/rnn.tflearn')\n",
    "    \n",
    "    #test to predict lable for just one image\n",
    "    #t = []\n",
    "    #t.append(X_train[0])\n",
    "    #print(model.predict_label(t))\n",
    "    results =  model.predict_label(X_test)\n",
    "    \n",
    "    #builder.save()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 257  | total loss: \u001b[1m\u001b[32m0.31003\u001b[0m\u001b[0m | time: 18.582s\n",
      "| Adam | epoch: 003 | loss: 0.31003 - acc: 0.8824 -- iter: 2720/2740\n",
      "Training Step: 258  | total loss: \u001b[1m\u001b[32m0.29866\u001b[0m\u001b[0m | time: 19.919s\n",
      "| Adam | epoch: 003 | loss: 0.29866 - acc: 0.8911 | val_loss: 0.26723 - val_acc: 0.9184 -- iter: 2740/2740\n",
      "--\n",
      "INFO:tensorflow:/root/rnn/checkpoints/rnn.tflearn is not in all_model_checkpoint_paths. Manually adding it.\n",
      "WARNING:tensorflow:Error encountered when serializing layer_tensor/LSTM.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef.\n",
      "'list' object has no attribute 'name'\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    input_length = 128\n",
    "    seq_length = 2\n",
    "    batch_size = 32\n",
    "    num_classes = 4\n",
    "    \n",
    "    root_path = '/mnt/c/Users/bk262/Desktop/last_layer3/'\n",
    "    label_mapping_path = './labels.txt' #labels.txt should NOT be in the root_path\n",
    "    \n",
    "#     X_from_image, y_from_image = get_train_data(data_root_path, label_mapping_path)\n",
    "#     X_train, X_test, y_train, y_test = get_data_with_seq(X_from_image, y_from_image, seq_length, num_classes, input_length)\n",
    "#     print(X_train.shape)\n",
    "    X_train, X_test, y_train, y_test = get_data(root_path, label_mapping_path)\n",
    "    print(X_train.shape)\n",
    "    print(y_train.shape)\n",
    "    print(X_test.shape)\n",
    "    print(y_test.shape)\n",
    "    results = train(X_train, y_train, X_test, y_test, seq_length, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(686, 3)\n",
      "686\n",
      "686\n"
     ]
    }
   ],
   "source": [
    "print(results.shape)\n",
    "results = np.array(results)\n",
    "print(len(results[:,0]))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.92857143,  0.90833333,  0.95081967])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "y_pred = results[:,0]\n",
    "cmat = confusion_matrix(y_true, y_pred)\n",
    "cmat\n",
    "cmat.diagonal()/cmat.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.9285714285714286\n",
      "1\n",
      "0.9083333333333333\n",
      "2\n",
      "0.9508196721311475\n"
     ]
    }
   ],
   "source": [
    "for k in range(0, 3):\n",
    "    count = 0\n",
    "    counti = 0\n",
    "    for i in range(0, len(y_true)):\n",
    "        if(y_true[i]==k):\n",
    "            counti=counti+1\n",
    "            if(y_pred[i]==k):\n",
    "                count = count+1\n",
    "    print(k)\n",
    "    print(count/counti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [python3]",
   "language": "python",
   "name": "Python [python3]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
